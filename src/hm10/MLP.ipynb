{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T11:30:36.673334Z",
     "iopub.status.busy": "2021-05-19T11:30:36.672690Z",
     "iopub.status.idle": "2021-05-19T11:30:43.495621Z",
     "shell.execute_reply": "2021-05-19T11:30:43.494984Z"
    },
    "id": "0trJmd6DjqBZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7NAbSZiaoJ4z"
   },
   "source": [
    "Download dữ liệu chữ số viết tay MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T11:30:43.501155Z",
     "iopub.status.busy": "2021-05-19T11:30:43.500509Z",
     "iopub.status.idle": "2021-05-19T11:30:44.026366Z",
     "shell.execute_reply": "2021-05-19T11:30:44.026834Z"
    },
    "id": "JqFRS6K07jJs"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-18 09:37:11.333785: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1760780231.521768      77 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1760780231.572493      77 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Chuẩn bị dữ liệu\n",
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# Chuyển đổi sang định dạng float32.\n",
    "x_train, x_test = np.array(x_train, np.float32), np.array(x_test, np.float32)\n",
    "# Chuẩn hóa ảnh từ from [0, 255] to [0, 1].\n",
    "x_train, x_test = x_train / 255., x_test / 255.\n",
    "x_train, x_test, y_train, y_test = torch.from_numpy(x_train), torch.from_numpy(x_test), torch.from_numpy(y_train).type(torch.LongTensor), torch.from_numpy(y_test).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000])\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "jS1f1TsVxoj6"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "trainloader = []\n",
    "for (i,j) in zip(x_train, y_train):\n",
    "    trainloader.append([i,j])\n",
    "trainloader = torch.utils.data.DataLoader(trainloader, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "testloader = []\n",
    "for (i,j) in zip(x_test, y_test):\n",
    "    testloader.append([i,j])\n",
    "testloader = torch.utils.data.DataLoader(testloader, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Ps36LD2btm0W"
   },
   "outputs": [],
   "source": [
    "num_features = 784\n",
    "n_hidden_1 = 512\n",
    "n_hidden_2 = 128\n",
    "n_hidden_3 = 32\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar0KFOo-mjsn"
   },
   "source": [
    "Sử dụng các tham số ở trên để xây dựng mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-05-19T11:30:44.902515Z",
     "iopub.status.busy": "2021-05-19T11:30:44.901796Z",
     "iopub.status.idle": "2021-05-19T11:30:45.195908Z",
     "shell.execute_reply": "2021-05-19T11:30:45.195388Z"
    },
    "id": "h3IKyzTCDNGo"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "                                nn.Linear(num_features, n_hidden_1),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(n_hidden_1, n_hidden_2),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(n_hidden_2, n_hidden_3),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(n_hidden_3, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "t9ns5fidtz-t"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T11:30:45.235727Z",
     "iopub.status.busy": "2021-05-19T11:30:45.235098Z",
     "iopub.status.idle": "2021-05-19T11:31:05.875247Z",
     "shell.execute_reply": "2021-05-19T11:31:05.875663Z"
    },
    "executionInfo": {
     "elapsed": 12045,
     "status": "ok",
     "timestamp": 1630204831765,
     "user": {
      "displayName": "Nam Cao Hải",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64",
      "userId": "02198006735637931468"
     },
     "user_tz": -420
    },
    "id": "i-2pkctU_Ci7",
    "outputId": "ad91b93e-0f6d-492f-f9de-568d383321cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 0.001\n",
      "[2,  2000] loss: 0.000\n",
      "[3,  2000] loss: 0.000\n",
      "[4,  2000] loss: 0.000\n",
      "[5,  2000] loss: 0.000\n",
      "[6,  2000] loss: 0.000\n",
      "[7,  2000] loss: 0.000\n",
      "[8,  2000] loss: 0.000\n",
      "[9,  2000] loss: 0.000\n",
      "[10,  2000] loss: 0.000\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # load input và labels\n",
    "        input, labels = data\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_flatten = input.reshape((len(input), -1))\n",
    "\n",
    "        #print (input_flatten.shape)\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(input_flatten)\n",
    "        #print(labels.shape)\n",
    "        #print(input.shape)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "qTG2aSROu4kK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# do đang thực hiện việc dự đoán nên ko cần tính đạo hàm\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data\n",
    "        #print(inputs.shape)\n",
    "        input_flatten = inputs.reshape(len(inputs), -1)\n",
    "        #print(input_flatten.shape)\n",
    "        # chạy hàm dự đoán\n",
    "        outputs = net(input_flatten)\n",
    "        # the class với giá trị xác suất cao nhất là đâu ra dự đoán\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHXvZHDXOhMW"
   },
   "source": [
    "## Save and load model<br>\n",
    "Trình bày 1 trong các các lưu model và load model trong PyTorch\n",
    "\n",
    "1.   Lưu model<br>\n",
    "```\n",
    "torch.save(model.state_dict(), PATH)\n",
    "```\n",
    "trong đó PATH là đường dẫn tự định nghĩa\n",
    "2.   Load model <br>\n",
    "\n",
    "*   Trước tiên phải định nghĩa model trước. Model được định nghĩa phải giống hệt với model đã được lưu lại. Như ví dụ trong bài này, thì sẽ thực hiện như sau: \n",
    "```\n",
    "model = Net()\n",
    "```\n",
    "*   Load trọng số đã được học vào mô hình<br>\n",
    "```\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "# vô hiệu hóa các layer như Dropout hay BatchNorm \n",
    "model.eval()\n",
    "```\n",
    "3. Có thể tham khảo thêm các phương pháp lưu và load model tại: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "lhSsevChOxXE"
   },
   "outputs": [],
   "source": [
    "# SAVE MODEL PARAM\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "\n",
    "torch.save(net.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (net): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Net()                     # tạo lại cùng kiến trúc\n",
    "net.load_state_dict(torch.load('model_weights.pth'))\n",
    "net.eval()                      # chuyển sang chế độ đánh giá (bỏ dropout, batchnorm update)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.0.weight \t torch.Size([512, 784])\n",
      "net.0.bias \t torch.Size([512])\n",
      "net.2.weight \t torch.Size([128, 512])\n",
      "net.2.bias \t torch.Size([128])\n",
      "net.4.weight \t torch.Size([32, 128])\n",
      "net.4.bias \t torch.Size([32])\n",
      "net.6.weight \t torch.Size([10, 32])\n",
      "net.6.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load('model_weights.pth')\n",
    "for name, param in state_dict.items():\n",
    "    print(name, \"\\t\", param.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0292,  0.0328,  0.0089,  ...,  0.0335,  0.0132,  0.0034],\n",
      "        [ 0.0312, -0.0050,  0.0105,  ..., -0.0176, -0.0019,  0.0340],\n",
      "        [ 0.0100,  0.0305, -0.0286,  ...,  0.0175,  0.0234, -0.0344],\n",
      "        ...,\n",
      "        [ 0.0100, -0.0212,  0.0329,  ..., -0.0322, -0.0221,  0.0110],\n",
      "        [ 0.0247, -0.0315, -0.0162,  ...,  0.0035, -0.0262,  0.0063],\n",
      "        [ 0.0165, -0.0332, -0.0343,  ...,  0.0119, -0.0112,  0.0330]])\n"
     ]
    }
   ],
   "source": [
    "print(state_dict['net.0.weight'])\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MLP.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
