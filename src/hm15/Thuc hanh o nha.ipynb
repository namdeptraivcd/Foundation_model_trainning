{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thực hành ở nhà Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoàn thiện hàm huấn luyện cho mạng Transformer và tiến hành huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cài đặt giải thuật tối ưu và huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-10-30 16:48:27--  https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/english.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘raw.githubusercontent.com’\n",
      "mv: cannot stat 'english.txt': No such file or directory\n",
      "--2025-10-30 16:48:59--  https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/french.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘raw.githubusercontent.com’\n",
      "--2025-10-30 16:49:31--  http://data/french.txt\n",
      "Resolving data (data)... failed: Temporary failure in name resolution.\n",
      "wget: unable to resolve host address ‘data’\n",
      "mv: cannot stat 'french.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir data\n",
    "!wget https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/english.txt\n",
    "!mv english.txt data\n",
    "!wget https://raw.githubusercontent.com/SamLynnEvans/Transformer/master/data/french.txt data/french.txt\n",
    "!mv french.txt data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedder (nn.Module): # vector meaning\n",
    "    def __init__ (self, vocab_size, dim):\n",
    "        super().__init__()  \n",
    "        self.embed_vector = nn.Embedding(vocab_size, dim)\n",
    "\n",
    "    def forward (self, x):\n",
    "        return self.embed_vector(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return vector embedding include meaning and position\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self,dim, max_seq = 300):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "\n",
    "        positional_embedding = torch.zeros(max_seq, dim)\n",
    "\n",
    "        position = torch.arange(0, max_seq).unsqueeze(1).float()\n",
    "        div_term = torch.exp(torch.arange(0, dim, 2).float() * -(math.log(10000)/dim))\n",
    "\n",
    "        positional_embedding[:, 0::2] = torch.sin(position * div_term)\n",
    "        positional_embedding[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        positional_embedding = positional_embedding.unsqueeze(0)\n",
    "        self.register_buffer('positional_embedding', positional_embedding)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x* math.sqrt(self.dim)\n",
    "\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        x = x + self.positional_embedding[:, :seq_len].to(device)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multihead Attention\n",
    "def attention(q, k, v, dim, mask = None, dropout = None):\n",
    "    score = torch.matmul(q, k.transpose(-2, -1))/math.sqrt(dim) # batch-seq-seq\n",
    "    if mask is not None:\n",
    "\n",
    "        score = score.masked_fill(mask == 0, float('-inf'))\n",
    "    self_attention = F.softmax(score, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        self_attention = dropout(self_attention)\n",
    "    \n",
    "    vector_context = torch.matmul(self_attention, v)\n",
    "    return vector_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.dim_head = dim//heads  \n",
    "        self.heads = heads\n",
    "        self.q_linear = nn.Linear(self.dim, self.dim)\n",
    "        self.k_linear = nn.Linear(self.dim, self.dim)\n",
    "        self.v_linear = nn.Linear(self.dim, self.dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(dim, dim)\n",
    "\n",
    "    def forward(self, q, k, v, mask = None): #inputs shape: batch-seq-dim\n",
    "        batch, sequence_length, dim = q.shape\n",
    "\n",
    "        q = self.q_linear(q)\n",
    "        k = self.k_linear(k)\n",
    "        v = self.v_linear(v)\n",
    "\n",
    "        q = q.view(batch, sequence_length, self.heads, self.dim_head).transpose(1, 2)\n",
    "        k = k.view(batch, sequence_length, self.heads, self.dim_head).transpose(1, 2)\n",
    "        v = v.view(batch, sequence_length, self.heads, self.dim_head).transpose(1, 2)\n",
    "\n",
    "\n",
    "        vector_context = attention(q, k, v, self.dim_head, mask, self.dropout) # batch - head - sequence - dimhead\n",
    "\n",
    "        vector_context = vector_context.transpose(1, 2).contiguous().view(batch, sequence_length, dim)\n",
    "        return self.out(vector_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim, d_ff = 2048, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(dim, d_ff),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Dropout(dropout),\n",
    "                                 nn.Linear(d_ff, dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Normalization(nn.Module):\n",
    "    def __init__(self, dim, eps = 1e-6):\n",
    "        super().__init__()\n",
    "\n",
    "        self.alpha = nn.Parameter(torch.ones(dim))\n",
    "        self.bias = nn.Parameter(torch.zeros(dim))\n",
    "\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        norm = self.alpha * (x-x.mean(dim = -1, keepdim = True))/(x.std(dim = -1, keepdim=True) + self.eps)  + self.bias\n",
    "        return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.ff = FeedForward(dim)\n",
    "        self.norm_1 = Normalization(dim) # Should be 2 different norm layer because normalization in each layer different\n",
    "        self.norm_2 = Normalization(dim)\n",
    "        self.AttentionLayer = MultiHeadAttention(heads, dim, dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward (self, x, mask):\n",
    "        residual = x\n",
    "        x = self.AttentionLayer(x, x, x, mask)\n",
    "        x = residual + self.dropout(x)\n",
    "        x = self.norm_1(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.ff(x) \n",
    "        x = residual + self.dropout(x)\n",
    "        x = self.norm_2(x)\n",
    "        return x\n",
    "\n",
    "class Encoder():\n",
    "    def __init__(self, vocab_size, dim, heads, num_layers =6 , dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.meaning = Embedder(vocab_size, dim)\n",
    "        self.postional_embedding = PositionalEmbedding(dim)\n",
    "        self.encoder_layers == nn.ModuleList([\n",
    "            EncoderBlock(dim, heads, dropout)\n",
    "            for _ in range (num_layers)\n",
    "        ])\n",
    "        self.norm = Normalization(dim)\n",
    "    \n",
    "    def forward (self, src, mask):\n",
    "        x = self.meaning(src) # vector meaning\n",
    "        x= self.postional_embedding(x)  # vector meaning + vector position\n",
    "        for layer in self.encoder_layers:\n",
    "            x = layer(x, mask)\n",
    "        encoder_output = self.norm(x)\n",
    "        return encoder_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.attention_layer = MultiHeadAttention(heads, dim)\n",
    "        self.norm_1 = Normalization(dim)\n",
    "        self.cross_attention = MultiHeadAttention(heads, dim)\n",
    "        self.norm_2 = Normalization(dim)\n",
    "        self.ff = FeedForward(dim)\n",
    "        self.norm_3 = Normalization(dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward (self, x, encoder_output, target_mask, src_mask):\n",
    "        residual = x\n",
    "        x = self.attention_layer(x, x, x, target_mask)\n",
    "        x = residual + self.dropout(x)\n",
    "\n",
    "        x = self.norm_1(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.cross_attention(x, encoder_output, encoder_output, src_mask)\n",
    "        x = residual + self.dropout(x)\n",
    "\n",
    "        x = self.norm_2(x)\n",
    "\n",
    "        residual = x\n",
    "        x = self.ff(x)\n",
    "        x = self.dropout(x) + residual\n",
    "\n",
    "        return self.norm_3(x)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, dim, heads, num_layers):\n",
    "        super().__init__()\n",
    "        self.meaning = Embedder(vocab_size, dim)\n",
    "        self.position = PositionalEmbedding(dim)\n",
    "        self.decoder_layers = nn.ModuleList(DecoderBlock(dim, heads) for _ in range(num_layers))\n",
    "        self.norm = Normalization(dim)\n",
    "    def forward(self, x, encoder_output, target_mask, src_mask):\n",
    "        x = self.meaning(x) # vector_meaning\n",
    "        x = self.position(x) # vector_meaning + position\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            x = layer(x, encoder_output, target_mask, src_mask)\n",
    "        decoder_output = self.norm(x)\n",
    "        return decoder_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab, target_vocab, dim, heads, num_layer):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab, dim, heads, num_layer)\n",
    "        self.decoder = Decoder(target_vocab, dim, heads, num_layer)\n",
    "        self.out = nn.Linear(dim, target_vocab)\n",
    "    def forward(self, src, target, src_mask, target_mask):\n",
    "        encoder_output = self.encoder(src, src_mask)\n",
    "        decoder_output = self.decoder(target, encoder_output, target_mask, src_mask)\n",
    "        output = self.out(decoder_output)\n",
    "        \n",
    "        return output  # Softmax will be performed automatically by our loss_function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPROCESSING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "class tokennize(object):\n",
    "    def __init__(self, lang):\n",
    "        self.nlp = spacy.load(lang)\n",
    "\n",
    "    def tokenizer (self, sentence):\n",
    "        sentence = re.sub(r\"[\\*\\\"“”\\n\\\\…\\+\\-\\/\\=\\(\\)‘•:\\[\\]\\|’\\!;]\", \" \", str(sentence))\n",
    "        sentence = re.sub(r\"[ ]+\", \" \", sentence)\n",
    "        sentence = re.sub(r\"\\!+\", \"!\", sentence)\n",
    "        sentence = re.sub(r\"\\,+\", \",\", sentence)\n",
    "        sentence = re.sub(r\"\\?+\", \"?\", sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return [tok.text for tok in self.nlp.tokenizer(sentence) if tok.text != \" \"]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e8067cb0390>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchtext/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e8067baf9d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchtext/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e8067b478d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchtext/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e8067b88a10>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchtext/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e8067bbd850>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torchtext/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torchtext==0.17.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchtext'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_126/3747339803.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbuild_vocab_from_iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchtext'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import spacy\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def nopeak_mask(size, device=device):\n",
    "    \"\"\"\n",
    "    Returns a mask for preventing attention to future tokens.\n",
    "    Shape expected by downstream: (1, size, size) (broadcastable)\n",
    "    \"\"\"\n",
    "    # upper triangular with 1s above diagonal\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "    mask = torch.from_numpy(np_mask) == 0  # True where allowed\n",
    "    return mask.to(device)\n",
    "\n",
    "def create_masks(src, trg, src_pad, trg_pad, device=device):\n",
    "    \"\"\"\n",
    "    src: LongTensor shape (batch, src_len)\n",
    "    trg: LongTensor shape (batch, trg_len)  OR None for inference\n",
    "    Returns: src_mask (batch,1,src_len), trg_mask (batch,1,trg_len, trg_len) or None\n",
    "    \"\"\"\n",
    "    # src_mask: (batch, 1, src_len)\n",
    "    src_mask = (src != src_pad).unsqueeze(1).to(device)\n",
    "\n",
    "    if trg is not None:\n",
    "        # trg_mask: (batch, 1, trg_len)\n",
    "        trg_mask = (trg != trg_pad).unsqueeze(1).to(device)  # (batch,1,trg_len)\n",
    "        seq_len = trg.size(1)\n",
    "        np_mask = nopeak_mask(seq_len, device)  # (1, seq_len, seq_len)\n",
    "        # combine padding mask and subsequent mask\n",
    "        # Need to broadcast trg_mask to (batch, seq_len) -> (batch, 1, seq_len) & np_mask (1, seq_len, seq_len)\n",
    "        # final shape: (batch, seq_len, seq_len) after broadcasting; some models expect (batch, 1, seq_len, seq_len) - adapt as needed\n",
    "        trg_mask = trg_mask & np_mask  # broadcasting: (batch,1,seq_len) & (1,seq_len,seq_len) -> (batch, seq_len, seq_len) because of alignment\n",
    "        # For compatibility with many implementations, return shape (batch, 1, seq_len, seq_len)\n",
    "        trg_mask = trg_mask.unsqueeze(1)  # (batch,1,seq_len,seq_len)\n",
    "    else:\n",
    "        trg_mask = None\n",
    "\n",
    "    return src_mask, trg_mask\n",
    "\n",
    "# === Batch-sizing helper retained (optional) ===\n",
    "# If you want dynamic batching by tokens (like original), you can keep this function and use it when creating batches.\n",
    "global max_src_in_batch, max_tgt_in_batch\n",
    "def batch_size_fn(new, count, sofar):\n",
    "    \"Keep augmenting batch and calculate total number of tokens + padding.\"\n",
    "    global max_src_in_batch, max_tgt_in_batch\n",
    "    if count == 1:\n",
    "        max_src_in_batch = 0\n",
    "        max_tgt_in_batch = 0\n",
    "    max_src_in_batch = max(max_src_in_batch,  len(new['src']))\n",
    "    max_tgt_in_batch = max(max_tgt_in_batch,  len(new['trg']) + 2)\n",
    "    src_elements = count * max_src_in_batch\n",
    "    tgt_elements = count * max_tgt_in_batch\n",
    "    return max(src_elements, tgt_elements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "# Simple wrapper to get spacy tokenizer\n",
    "def get_spacy_tokenizer(lang_code):\n",
    "    # lang_code e.g., 'en_core_web_sm' or 'en'\n",
    "    # Accept either 'en' or 'en_core_web_sm' in opt.src_lang\n",
    "    name = lang_code if '_' in lang_code else f\"{lang_code}_core_web_sm\"\n",
    "    try:\n",
    "        nlp = spacy.load(name)\n",
    "    except Exception as e:\n",
    "        # user may need to install the model\n",
    "        raise RuntimeError(f\"Spacy model '{name}' not found. Install with: python -m spacy download {name}\") from e\n",
    "\n",
    "    def tokenize_text(text):\n",
    "        return [tok.text.lower() for tok in nlp(text)]\n",
    "    return tokenize_text\n",
    "\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_lines, trg_lines, src_tok_fn, trg_tok_fn, src_vocab, trg_vocab, add_sos_eos=True):\n",
    "        assert len(src_lines) == len(trg_lines)\n",
    "        self.src_lines = src_lines\n",
    "        self.trg_lines = trg_lines\n",
    "        self.src_tok_fn = src_tok_fn\n",
    "        self.trg_tok_fn = trg_tok_fn\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.add_sos_eos = add_sos_eos\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_lines)\n",
    "def __getitem__(self, idx):\n",
    "        src_text = self.src_lines[idx]\n",
    "        trg_text = self.trg_lines[idx]\n",
    "        src_tokens = self.src_tok_fn(src_text)\n",
    "        trg_tokens = self.trg_tok_fn(trg_text)\n",
    "        if self.add_sos_eos:\n",
    "            trg_tokens = ['<sos>'] + trg_tokens + ['<eos>']\n",
    "        # numericalize lazily in collate\n",
    "        return {'src': src_tokens, 'trg': trg_tokens}\n",
    "\n",
    "def yield_tokens(lines, tokenizer):\n",
    "    for line in lines:\n",
    "        yield tokenizer(line)\n",
    "\n",
    "def build_vocabs(opt, src_lines, trg_lines, src_tok_fn, trg_tok_fn, min_freq=2):\n",
    "    specials = ['<pad>', '<sos>', '<eos>', '<unk>']\n",
    "    src_vocab = build_vocab_from_iterator(yield_tokens(src_lines, src_tok_fn),\n",
    "                                         specials=specials,\n",
    "                                         special_first=True)\n",
    "    trg_vocab = build_vocab_from_iterator(yield_tokens(trg_lines, trg_tok_fn),\n",
    "                                         specials=specials,\n",
    "                                         special_first=True)\n",
    "\n",
    "    # set default index for unknown tokens\n",
    "    src_vocab.set_default_index(src_vocab['<unk>'])\n",
    "    trg_vocab.set_default_index(trg_vocab['<unk>'])\n",
    "    return src_vocab, trg_vocab\n",
    "\n",
    "def numericalize(tokens_list, vocab):\n",
    "    return [vocab[token] for token in tokens_list]\n",
    "\n",
    "def collate_fn(batch, src_vocab, trg_vocab, max_strlen=None, device=device):\n",
    "    # batch is a list of {'src': [...tokens...], 'trg': [...tokens...]}\n",
    "    src_batch = [torch.tensor(numericalize(x['src'], src_vocab), dtype=torch.long) for x in batch]\n",
    "    trg_batch = [torch.tensor(numericalize(x['trg'], trg_vocab), dtype=torch.long) for x in batch]\n",
    "\n",
    "    # optionally filter by max length (similar to your mask earlier)\n",
    "    if max_strlen is not None:\n",
    "        keep_indices = [i for i, (s, t) in enumerate(zip(src_batch, trg_batch))\n",
    "                        if s.size(0) <= max_strlen and t.size(0) <= max_strlen]\n",
    "        if len(keep_indices) != len(batch):\n",
    "            src_batch = [src_batch[i] for i in keep_indices]\n",
    "            trg_batch = [trg_batch[i] for i in keep_indices]\n",
    "\n",
    "    # pad sequences to longest in batch (pad value is index of '<pad>')\n",
    "    pad_idx_src = src_vocab['<pad>']\n",
    "    pad_idx_trg = trg_vocab['<pad>']\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=pad_idx_src).to(device)  # (batch, src_len)\n",
    "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=pad_idx_trg).to(device)  # (batch, trg_len)\n",
    "\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "def read_data(opt):\n",
    "    \"\"\"Read text files into lists of lines (keeps your original API)\"\"\"\n",
    "    if opt.src_data is not None:\n",
    "        try:\n",
    "            opt.src_data = open(opt.src_data).read().strip().split('\\n')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"error: '{opt.src_data}' file not found\") from e\n",
    "\n",
    "    if opt.trg_data is not None:\n",
    "        try:\n",
    "            opt.trg_data = open(opt.trg_data).read().strip().split('\\n')\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"error: '{opt.trg_data}' file not found\") from e\n",
    "        \n",
    "def create_dataset_and_dataloader(opt, device=device):\n",
    "    \"\"\"\n",
    "    Replaces your create_fields + create_dataset workflow.\n",
    "    Returns: dataloader, src_vocab, trg_vocab, pad indices, dataset length\n",
    "    \"\"\"\n",
    "    print(\"Creating tokenizers...\")\n",
    "    src_lang = opt.src_lang #[0:2]\n",
    "    trg_lang = opt.trg_lang#[0:2]\n",
    "    src_tok = get_spacy_tokenizer(src_lang)\n",
    "    trg_tok = get_spacy_tokenizer(trg_lang)\n",
    "\n",
    "    # We expect opt.src_data and opt.trg_data to be lists of lines (read_data should be called first)\n",
    "    src_lines = opt.src_data\n",
    "    trg_lines = opt.trg_data\n",
    "\n",
    "    print(\"Building vocabs...\")\n",
    "    src_vocab, trg_vocab = build_vocabs(opt, src_lines, trg_lines, src_tok, trg_tok)\n",
    "\n",
    "    print(\"Creating dataset...\")\n",
    "    dataset = TranslationDataset(src_lines, trg_lines, src_tok, trg_tok, src_vocab, trg_vocab, add_sos_eos=True)\n",
    "\n",
    "    # create DataLoader with custom collate that closes over vocabs and max_strlen\n",
    "    my_collate = partial(collate_fn, src_vocab=src_vocab, trg_vocab=trg_vocab, max_strlen=getattr(opt, 'max_strlen', None))\n",
    "    dataloader = DataLoader(dataset, batch_size=opt.batchsize, shuffle=True, collate_fn=my_collate)\n",
    "\n",
    "    # pad ids\n",
    "    opt.src_pad = src_vocab['<pad>']\n",
    "    opt.trg_pad = trg_vocab['<pad>']\n",
    "\n",
    "    # compute train_len like original get_len (number of batches)\n",
    "    train_len = len(dataloader)\n",
    "\n",
    "    return dataloader, src_vocab, trg_vocab, opt.src_pad, opt.trg_pad, train_len\n",
    "\n",
    "# Example helper to iterate get_len as before (if you want compatibility)\n",
    "def get_len(dataloader):\n",
    "    for i, b in enumerate(dataloader):\n",
    "        pass\n",
    "    return i\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "class CosineWithRestarts(torch.optim.lr_scheduler._LRScheduler):\n",
    "    \"\"\"\n",
    "    Cosine annealing with restarts.\n",
    "    Parameters\n",
    "    ----------\n",
    "    optimizer : torch.optim.Optimizer\n",
    "    T_max : int\n",
    "        The maximum number of iterations within the first cycle.\n",
    "    eta_min : float, optional (default: 0)\n",
    "        The minimum learning rate.\n",
    "    last_epoch : int, optional (default: -1)\n",
    "        The index of the last epoch.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 optimizer: torch.optim.Optimizer,\n",
    "                 T_max: int,\n",
    "                 eta_min: float = 0.,\n",
    "                 last_epoch: int = -1,\n",
    "                 factor: float = 1.) -> None:\n",
    "        # pylint: disable=invalid-name\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        self.factor = factor\n",
    "        self._last_restart: int = 0\n",
    "        self._cycle_counter: int = 0\n",
    "        self._cycle_factor: float = 1.\n",
    "        self._updated_cycle_len: int = T_max\n",
    "        self._initialized: bool = False\n",
    "        super(CosineWithRestarts, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "def get_lr(self):\n",
    "        \"\"\"Get updated learning rate.\"\"\"\n",
    "        # HACK: We need to check if this is the first time get_lr() was called, since\n",
    "        # we want to start with step = 0, but _LRScheduler calls get_lr with\n",
    "        # last_epoch + 1 when initialized.\n",
    "        if not self._initialized:\n",
    "            self._initialized = True\n",
    "            return self.base_lrs\n",
    "\n",
    "        step = self.last_epoch + 1\n",
    "        self._cycle_counter = step - self._last_restart\n",
    "\n",
    "        lrs = [\n",
    "            (\n",
    "                self.eta_min + ((lr - self.eta_min) / 2) *\n",
    "                (\n",
    "                    np.cos(\n",
    "                        np.pi *\n",
    "                        ((self._cycle_counter) % self._updated_cycle_len) /\n",
    "                        self._updated_cycle_len\n",
    "                    ) + 1\n",
    "                )\n",
    "            ) for lr in self.base_lrs\n",
    "        ]\n",
    "\n",
    "        if self._cycle_counter % self._updated_cycle_len == 0:\n",
    "            # Adjust the cycle length.\n",
    "            self._cycle_factor *= self.factor\n",
    "            self._cycle_counter = 0\n",
    "            self._updated_cycle_len = int(self._cycle_factor * self.T_max)\n",
    "            self._last_restart = step\n",
    "\n",
    "        return lrs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(opt, src_vocab, trg_vocab):\n",
    "\n",
    "    assert opt.d_model % opt.heads == 0\n",
    "    assert opt.dropout < 1\n",
    "\n",
    "    model = Transformer(src_vocab, trg_vocab, opt.d_model, opt.n_layers, opt.heads)\n",
    "\n",
    "    if opt.load_weights is not None:\n",
    "        print(\"loading pretrained weights...\")\n",
    "        model.load_state_dict(torch.load(f'{opt.load_weights}/model_weights'))\n",
    "    else:\n",
    "        for p in model.parameters():\n",
    "            if p.dim() > 1:\n",
    "                nn.init.xavier_uniform_(p)\n",
    "\n",
    "    if opt.device == 0:\n",
    "        model = model.cuda()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0Q2qOSP7jGb5",
    "outputId": "8f7ea0ba-e993-4a04-f528-c2afd0eadc60"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "error: 'data/english.txt' file not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 89\u001b[0m, in \u001b[0;36mread_data\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 89\u001b[0m     opt\u001b[38;5;241m.\u001b[39msrc_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msrc_data\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Users/miniconda3/envs/ai/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/english.txt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 123\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# for asking about further training use while true loop, and return\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 123\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 103\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mno_cuda \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    101\u001b[0m opt\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m--> 103\u001b[0m \u001b[43mread_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m dataloader, src_vocab, trg_vocab, opt\u001b[38;5;241m.\u001b[39msrc_pad, opt\u001b[38;5;241m.\u001b[39mtrg_pad, opt\u001b[38;5;241m.\u001b[39mtrain_len \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    106\u001b[0m     create_dataset_and_dataloader(opt, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain steps per epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt\u001b[38;5;241m.\u001b[39mtrain_len\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 91\u001b[0m, in \u001b[0;36mread_data\u001b[0;34m(opt)\u001b[0m\n\u001b[1;32m     89\u001b[0m         opt\u001b[38;5;241m.\u001b[39msrc_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(opt\u001b[38;5;241m.\u001b[39msrc_data)\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 91\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mopt\u001b[38;5;241m.\u001b[39msrc_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m file not found\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mtrg_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: error: 'data/english.txt' file not found"
     ]
    }
   ],
   "source": [
    "\"\"\" BAI TAP VE NHA \"\"\"\n",
    "\n",
    "import time\n",
    "import os\n",
    "\n",
    "class Opt:\n",
    "    pass\n",
    "\n",
    "def train_model(model, dataloader, opt):\n",
    "    ########################\n",
    "\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    # Định nghĩa criterion bên trong hàm\n",
    "    criterion = nn.CrossEntropyLoss(ignore_index=opt.trg_pad)\n",
    "\n",
    "    for epoch in range(opt.epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        # 1. Lặp qua dataloader\n",
    "        for i, batch in enumerate(dataloader):\n",
    "\n",
    "            # 2. Lấy src, trg (đã là batch_first=True và trên device từ collate_fn)\n",
    "            src, trg = batch\n",
    "\n",
    "            # trg_input là <sos>...word (ví dụ: [1, 5, 7, 9])\n",
    "            trg_input = trg[:, :-1]\n",
    "            # trg_output là word...<eos> (ví dụ: [5, 7, 9, 2])\n",
    "            trg_output = trg[:, 1:].contiguous().view(-1)\n",
    "\n",
    "            # 3. Tạo mặt nạ (masks) với đúng tham số\n",
    "            src_mask, trg_mask = create_masks(src, trg_input, opt.src_pad, opt.trg_pad, opt.device)\n",
    "\n",
    "            opt.optimizer.zero_grad()\n",
    "\n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "\n",
    "            preds_flat = preds.contiguous().view(-1, preds.size(-1))\n",
    "\n",
    "            loss = criterion(preds_flat, trg_output)\n",
    "            loss.backward()\n",
    "\n",
    "            opt.optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            if (i + 1) % opt.printevery == 0:\n",
    "                avg_loss = total_loss / opt.printevery\n",
    "                print(f\"Epoch [{epoch+1}/{opt.epochs}], Step [{i+1}/{opt.train_len}], Loss: {avg_loss:.4f}, Time: {time.time() - start:.2f}s\")\n",
    "                total_loss = 0\n",
    "                start = time.time()\n",
    "\n",
    "        #checkpoint\n",
    "        if opt.checkpoint > 0:\n",
    "            print(f\"--- epoch {epoch+1} finished, saving weights ---\")\n",
    "            if not os.path.exists('weights'):\n",
    "                os.makedirs('weights')\n",
    "            torch.save(model.state_dict(), f'weights/model_epoch_{epoch+1}.weights')\n",
    "\n",
    "    print(\"training complete.\")\n",
    "    ########################\n",
    "\n",
    "\n",
    "def main():\n",
    "    opt = Opt()\n",
    "    opt.src_data = \"data/english.txt\"\n",
    "    opt.trg_data = \"data/french.txt\"\n",
    "    opt.src_lang = \"en_core_web_sm\"\n",
    "    opt.trg_lang = 'fr_core_news_sm'\n",
    "    opt.epochs = 2\n",
    "    opt.d_model=512\n",
    "    opt.n_layers=6\n",
    "    opt.heads=8\n",
    "    opt.dropout=0.1\n",
    "    opt.batchsize=32\n",
    "    opt.printevery=100\n",
    "    opt.lr=0.0001\n",
    "    opt.max_strlen=80\n",
    "    opt.checkpoint = 0\n",
    "    opt.no_cuda = False\n",
    "    opt.load_weights = None\n",
    "\n",
    "    # opt.device = 0\n",
    "    # if opt.device == 0:\n",
    "    #     assert torch.cuda.is_available()\n",
    "\n",
    "    # read_data(opt)\n",
    "    # SRC, TRG = create_fields(opt)\n",
    "    # opt.train = create_dataset(opt, SRC, TRG)\n",
    "    # model = get_model(opt, len(SRC.vocab), len(TRG.vocab)).to(device)\n",
    "\n",
    "    # opt.optimizer = torch.optim.Adam(model.parameters(), lr=opt.lr, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "    # if opt.checkpoint > 0:\n",
    "    #     print(\"model weights will be saved every %d minutes and at end of epoch to directory weights/\"%(opt.checkpoint))\n",
    "\n",
    "    # train_model(model, opt)\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and not opt.no_cuda else \"cpu\")\n",
    "    opt.device = device\n",
    "\n",
    "    read_data(opt)\n",
    "\n",
    "    dataloader, src_vocab, trg_vocab, opt.src_pad, opt.trg_pad, opt.train_len = \\\n",
    "        create_dataset_and_dataloader(opt, device=device)\n",
    "\n",
    "    print(f\"Train steps per epoch: {opt.train_len}\")\n",
    "\n",
    "    model = get_model(opt, len(src_vocab), len(trg_vocab)).to(device)\n",
    "    opt.optimizer = torch.optim.Adam(\n",
    "        model.parameters(),\n",
    "        lr=opt.lr,\n",
    "        betas=(0.9, 0.98),\n",
    "        eps=1e-9\n",
    "    )\n",
    "\n",
    "    train_model(model, dataloader, opt)\n",
    "\n",
    "\n",
    "    # for asking about further training use while true loop, and return\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TransformerTut.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
