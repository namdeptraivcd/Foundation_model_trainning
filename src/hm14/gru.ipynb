{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"name":"gru.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"code","metadata":{"id":"Cx9VetpRcm8x","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630237618082,"user_tz":-420,"elapsed":5140,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}},"outputId":"ab2d9546-4c59-4baf-b9c9-895faae71284"},"source":["# cài đặt thư viện d2l\n","!pip install d2l==0.16.5"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting d2l==0.16.5\n","  Downloading d2l-0.16.5-py3-none-any.whl (77 kB)\n","\u001b[?25l\r\u001b[K     |████▎                           | 10 kB 24.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20 kB 32.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 77 kB 3.2 MB/s \n","\u001b[?25hRequirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.5) (1.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.5) (1.19.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.5) (2.23.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.5) (1.1.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from d2l==0.16.5) (3.2.2)\n","Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.5) (7.6.3)\n","Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.5) (5.1.1)\n","Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.5) (5.2.0)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.5) (4.10.1)\n","Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.5) (5.3.1)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->d2l==0.16.5) (5.6.1)\n","Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.16.5) (5.1.1)\n","Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.16.5) (5.5.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.16.5) (5.3.5)\n","Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->d2l==0.16.5) (5.0.5)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (57.4.0)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (2.6.1)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (0.7.5)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (0.8.1)\n","Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (4.8.0)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (4.4.2)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->jupyter->d2l==0.16.5) (0.2.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.1.0->ipykernel->jupyter->d2l==0.16.5) (0.2.0)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.5) (5.1.3)\n","Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.5) (1.0.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->d2l==0.16.5) (3.5.1)\n","Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.16.5) (2.6.0)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->jupyter->d2l==0.16.5) (4.7.1)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.5) (0.11.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.5) (2.11.3)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->d2l==0.16.5) (1.8.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==0.16.5) (22.2.1)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->d2l==0.16.5) (2.8.2)\n","Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->d2l==0.16.5) (0.7.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->d2l==0.16.5) (2.0.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.5) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.5) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->d2l==0.16.5) (2.4.7)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.5) (0.8.4)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.5) (0.5.0)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.5) (0.7.1)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.5) (4.0.0)\n","Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.5) (0.3)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->d2l==0.16.5) (1.4.3)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.5) (0.5.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->d2l==0.16.5) (21.0)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->d2l==0.16.5) (2018.9)\n","Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->d2l==0.16.5) (1.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.5) (2021.5.30)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.5) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.5) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->d2l==0.16.5) (3.0.4)\n","Installing collected packages: d2l\n","Successfully installed d2l-0.16.5\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":0,"id":"kKQJkLWGcm8y"},"source":["# Gated Recurrent Units (GRU)\n","\n","- Trong phần trước, chúng ta đã thảo luận cách tính gradient trong mạng nơ-ron hồi tiếp. Cụ thể ta đã biết rằng tích của một chuỗi dài các ma trận có thể dẫn đến việc gradient tiêu biến hoặc bùng nổ. Hãy điểm qua các tình huống thực tế thể hiện rõ hai bất thường đó:\n","\n"," - Ta có thể gặp tình huống mà những quan sát xuất hiện sớm có ảnh hưởng lớn đến việc dự đoán toàn bộ những quan sát trong tương lai. Xét một ví dụ có chút cường điệu, trong đó quan sát đầu tiên chứa giá trị tổng kiểm (checksum) và mục tiêu là kiểm tra xem liệu giá trị tổng kiểm đó có đúng hay không tại cuối chuỗi. Trong trường hợp này, ảnh hưởng của token đầu tiên là tối quan trọng. Do đó ta muốn có cơ chế để lưu trữ những thông tin quan trọng ban đầu trong ô nhớ. Nếu không, ta sẽ phải gán một giá trị gradient cực lớn cho quan sát ban đầu vì nó ảnh hưởng đến toàn bộ các quan sát tiếp theo.\n","- Một tình huống khác là khi một vài ký hiệu không chứa thông tin phù hợp. Ví dụ, khi phân tích một trang web, ta có thể gặp các mã HTML không giúp ích gì cho việc xác định thông tin được truyền tải. Do đó, ta cũng muốn có cơ chế để bỏ qua những ký hiệu như vậy trong các biểu diễn trạng thái tiềm ẩn.\n","- Ta cũng có thể gặp những khoảng ngắt giữa các phần trong một chuỗi. Ví dụ như những phần chuyển tiếp giữa các chương của một quyển sách, hay chuyển biến xu hướng giữa thị trường giá lên và thị trường giá xuống trong chứng khoán. Trong trường hợp này, sẽ tốt hơn nếu có một cách để xóa hay đặt lại các biểu diễn trạng thái ẩn về giá trị ban đầu\n","\n","Nhiều phương pháp đã được đề xuất để giải quyết những vấn đề trên. Một trong những phương pháp ra đời sớm nhất là Bộ nhớ ngắn hạn dài (Long Short Term Memory - LSTM) :cite:`Hochreiter.Schmidhuber.1997` and The gated recurrent unit (GRU)\n",":cite:`Cho.Van-Merrienboer.Bahdanau.ea.2014` là một biến thể gọn hơn của LSTM, thường có chất lượng tương đương và tính toán nhanh hơn đáng kể\n",". Trong bài này, ta sẽ bắt đầu với GRU do nó đơn giản hơn.\n","\n","## Gated Hidden State\n","\n","Sự khác biệt chính giữa RNN thông thường và GRU là GRU hỗ trợ việc kiểm soát trạng thái ẩn. Điều này có nghĩa là ta có các cơ chế được học để quyết định khi nào nên cập nhật và khi nào nên xóa trạng thái ẩn. Ví dụ, nếu ký tự đầu tiên có mức độ quan trọng cao, mô hình sẽ học để không cập nhật trạng thái ẩn sau lần quan sát đầu tiên. Tương tự, mô hình sẽ học cách bỏ qua những quan sát tạm thời không liên quan, cũng như cách xóa trạng thái ẩn khi cần thiết. Dưới đây ta sẽ thảo luận chi tiết vấn đề này.\n","\n","\n","### Reset Gate and Update Gate\n","\n","Đầu tiên ta giới thiệu cổng xóa và cổng cập nhật. Ta thiết kế chúng thành các vector có các phần tử trong khoảng  (0,1)  để có thể biểu diễn các tổ hợp lồi. Chẳng hạn, một biến xóa cho phép kiểm soát bao nhiêu phần của trạng thái trước đây được giữ lại. Tương tự, một biến cập nhật cho phép kiểm soát bao nhiêu phần của trạng thái mới sẽ giống trạng thái cũ.\n","\n","Ta bắt đầu bằng việc thiết kế các cổng tạo ra các biến này. :numref:`fig_gru_1` minh họa các đầu vào cho cả cổng xóa và cổng cập nhật trong GRU, với đầu vào ở bước thời gian hiện tại  $X_t$  và trạng thái ẩn ở bước thời gian trước đó $\\mathbf{H}_{t-1}$ . Đầu ra được tạo bởi một tầng kết nối đầy đủ với hàm kích hoạt sigmoid.\n","\n","![Computing the reset gate and the update gate in a GRU model.](https://github.com/d2l-ai/d2l-tensorflow-colab/blob/master/img/gru-1.svg?raw=1)\n",":label:`fig_gru_1`\n","\n","Tại bước thời gian  t , với đầu vào minibatch là\n","$\\mathbf{X}_t \\in \\mathbb{R}^{n \\times d}$ (số lượng mẫu:  n , số lượng đầu vào:  d) và trạng thái ẩn ở bước thời gian gần nhất là $\\mathbf{H}_{t-1} \\in \\mathbb{R}^{n \\times h}$ (số lượng trạng thái ẩn:  h). Cổng xóa $\\mathbf{R}_t \\in \\mathbb{R}^{n \\times h}$ và cổng cập nhật $\\mathbf{Z}_t \\in \\mathbb{R}^{n \\times h}$ được tính như sau: \n","\n","$$\n","\\begin{aligned}\n","\\mathbf{R}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xr} + \\mathbf{H}_{t-1} \\mathbf{W}_{hr} + \\mathbf{b}_r),\\\\\n","\\mathbf{Z}_t = \\sigma(\\mathbf{X}_t \\mathbf{W}_{xz} + \\mathbf{H}_{t-1} \\mathbf{W}_{hz} + \\mathbf{b}_z),\n","\\end{aligned}\n","$$\n","\n","với $\\mathbf{W}_{xr}, \\mathbf{W}_{xz} \\in \\mathbb{R}^{d \\times h}$ và\n","$\\mathbf{W}_{hr}, \\mathbf{W}_{hz} \\in \\mathbb{R}^{h \\times h}$ là các tham số trọng số và $\\mathbf{b}_r, \\mathbf{b}_z \\in \\mathbb{R}^{1 \\times h}$ là các hệ số điều chỉnh. Ta sẽ sử dụng hàm sigmoid để biến đổi các giá trị đầu vào nằm trong khoảng  (0,1) .\n","\n","#### Reset gate\n","\n","Ta bắt đầu bằng việc tích hợp cổng xóa với một cơ chế cập nhật trạng thái tiềm ẩn thông thường. Trong RNN thông thường, ta cập nhật trạng thái ẩn theo công thức:\n","$$\\mathbf{H}_t = \\tanh(\\mathbf{X}_t \\mathbf{W}_{xh} + \\mathbf{H}_{t-1}\\mathbf{W}_{hh} + \\mathbf{b}_h).$$\n","\n","Điều này về cơ bản giống với những gì đã thảo luận ở phần trước, mặc dù có thêm tính phi tuyến dưới dạng hàm  tanh  để đảm bảo rằng các giá trị trạng thái ẩn nằm trong khoảng  (−1,1) . Nếu muốn giảm ảnh hưởng của các trạng thái trước đó, ta có thể nhân  $\\mathbf{H}_{t-1}$   với  $R_t$  theo từng phần tử. Nếu các phần tử trong cổng xóa  $R_t$  có giá trị gần với  1 , kết quả sẽ giống RNN thông thường. Nếu tất cả các phần tử của cổng xóa  Rt  gần với  0 , trạng thái ẩn sẽ là đầu ra của một perceptron đa tầng với đầu vào là  $X_t$ . Bất kỳ trạng thái ẩn nào tồn tại trước đó đều được đặt lại về giá trị mặc định. Tại đây nó được gọi là trạng thái ẩn tiềm năng, và chỉ là tiềm năng vì ta vẫn cần kết hợp thêm đầu ra của cổng cập nhật.\n","\n","$$\\tilde{\\mathbf{H}}_t = \\tanh(\\mathbf{X}_t \\mathbf{W}_{xh} + \\left(\\mathbf{R}_t \\odot \\mathbf{H}_{t-1}\\right) \\mathbf{W}_{hh} + \\mathbf{b}_h).$$\n","\n","\n","Hình sau minh họa luồng tính toán sau khi áp dụng cổng xóa. Ký hiệu  ⊙  biểu thị phép nhân theo từng phần tử giữa các tensor\n","\n","![](https://d2l.aivivn.com/_images/gru_2.svg)\n","\n","#### Update gate\n","\n","Tiếp theo ta sẽ kết hợp hiệu ứng của cổng cập nhật  $Z_t$  như trong hình dưới. Cổng này xác định mức độ giống nhau giữa trạng thái mới  $H_t$  và trạng thái cũ  $\\mathbf{H}_{t-1}$ , cũng như mức độ trạng thái ẩn tiềm năng  $\\tilde{\\mathbf{H}}_t$  được sử dụng. Biến cổng (gating variable)  $Z_t$  được sử dụng cho mục đích này, bằng cách áp dụng tổ hợp lồi giữa trạng thái cũ và trạng thái tiềm năng. Ta có phương trình cập nhật cuối cùng cho GRU.\n","\n","$$\\mathbf{H}_t = \\mathbf{Z}_t \\odot \\mathbf{H}_{t-1}  + (1 - \\mathbf{Z}_t) \\odot \\tilde{\\mathbf{H}}_t.$$\n","\n","Nếu các giá trị trong cổng cập nhật  $Z_t$  bằng  1 , chúng ta chỉ đơn giản giữ lại trạng thái cũ. Trong trường hợp này, thông tin từ  $X_t$  về cơ bản được bỏ qua, tương đương với việc bỏ qua bước thời gian  $t$  trong chuỗi phụ thuộc. Ngược lại, nếu  $Z_t$  gần giá trị  0 , trạng thái ẩn  Ht  sẽ gần với trạng thái ẩn tiềm năng  $\\tilde{\\mathbf{H}}_t$ . Những thiết kế trên có thể giúp chúng ta giải quyết vấn đề tiêu biến gradient trong các mạng RNN và nắm bắt tốt hơn sự phụ thuộc xa trong chuỗi thời gian. Tóm lại, các mạng GRU có hai tính chất nổi bật sau:\n","\n","- Cổng xóa giúp nắm bắt các phụ thuộc ngắn hạn trong chuỗi thời gian.\n","- Cổng cập nhật giúp nắm bắt các phụ thuộc dài hạn trong chuỗi thời gian.\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"aFRK9ykdDjOS"},"source":["## Implementation from Scratch\n","\n","Để hiểu rõ hơn, hãy lập trình mô hình GRU từ đầu.\n"]},{"cell_type":"code","metadata":{"origin_pos":3,"tab":["tensorflow"],"id":"h3fkO1Cvcm80","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1630237621930,"user_tz":-420,"elapsed":1639,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}},"outputId":"6d115789-c836-4001-803f-4aec89b98e90"},"source":["import torch\n","from torch import nn\n","from d2l import torch as d2l\n","\n","batch_size, num_steps = 32, 35\n","train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Downloading ../data/timemachine.txt from http://d2l-data.s3-accelerate.amazonaws.com/timemachine.txt...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"origin_pos":4,"id":"ydHL2Wgycm82"},"source":["### Initializing Model Parameters\n","\n","Bước tiếp theo là khởi tạo các tham số mô hình. Ta khởi tạo các giá trị trọng số theo phân phối Gauss với phương sai  0.01  và thiết lập các hệ số điều chỉnh bằng  0 . Siêu tham số `num_hiddens` xác định số lượng đơn vị ẩn. Ta khởi tạo tất cả các trọng số và các hệ số điều chỉnh của cổng cập nhật, cổng xóa, và các trạng thái ẩn tiềm năng. Sau đó, gắn gradient cho tất cả các tham số.\n"]},{"cell_type":"code","metadata":{"origin_pos":7,"tab":["tensorflow"],"id":"J4umVsRxcm83","executionInfo":{"status":"ok","timestamp":1630237631724,"user_tz":-420,"elapsed":294,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}}},"source":["def get_params(vocab_size, num_hiddens, device):\n","    num_inputs = num_outputs = vocab_size\n","\n","    def normal(shape):\n","        return torch.randn(size=shape, device=device) * 0.01\n","\n","    def three():\n","        return (normal(\n","            (num_inputs, num_hiddens)), normal((num_hiddens, num_hiddens)),\n","                torch.zeros(num_hiddens, device=device))\n","\n","    W_xz, W_hz, b_z = three()  # Update gate parameters\n","    W_xr, W_hr, b_r = three()  # Reset gate parameters\n","    W_xh, W_hh, b_h = three()  # Candidate hidden state parameters\n","    # Output layer parameters\n","    W_hq = normal((None, None))\n","    b_q = torch.zeros(None, device=device)\n","    # Attach gradients\n","    params = [W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q]\n","    for param in params:\n","        param.requires_grad_(None)\n","    return params"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":8,"id":"dXozJDwZcm83"},"source":["### Defining the Model\n","\n","Bây giờ ta sẽ định nghĩa hàm khởi tạo trạng thái ẩn init_gru_state. Hàm này trả về một mảng ndarray chứa các giá trị bằng không với kích thước (kích thước batch, số đơn vị ẩn).\n"]},{"cell_type":"code","metadata":{"origin_pos":11,"tab":["tensorflow"],"id":"tO6QsH0Mcm84","executionInfo":{"status":"ok","timestamp":1630237635154,"user_tz":-420,"elapsed":290,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}}},"source":["def init_gru_state(batch_size, num_hiddens, device):\n","    return (torch.zeros((None, None), device=device),)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":12,"id":"wv7fCMbrcm84"},"source":["Giờ ta có thể định nghĩa mô hình GRU. Cấu trúc GRU cũng giống một khối RNN cơ bản nhưng có phương trình cập nhật phức tạp hơn."]},{"cell_type":"code","metadata":{"origin_pos":15,"tab":["tensorflow"],"id":"k84akpmBcm85","executionInfo":{"status":"ok","timestamp":1630237637087,"user_tz":-420,"elapsed":279,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}}},"source":["def gru(inputs, state, params):\n","    W_xz, W_hz, b_z, W_xr, W_hr, b_r, W_xh, W_hh, b_h, W_hq, b_q = params\n","    H, = state\n","    outputs = []\n","    for X in inputs:\n","        Z = None\n","        R = None\n","        H_tilda = None\n","        H = None\n","        Y = None\n","        outputs.append(Y)\n","    return torch.cat(outputs, dim=0), (H,)"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":16,"id":"-wQWwTGxcm85"},"source":["### Training and Prediction\n","\n","Việc huấn luyện và dự đoán cũng được thực hiện tương tự như với RNN. Sau khi huấn luyện một epoch, ta thu được perplexity và câu đầu ra như sau."]},{"cell_type":"code","metadata":{"origin_pos":18,"tab":["tensorflow"],"id":"RFsln58Tcm85"},"source":["vocab_size, num_hiddens, device = len(vocab), 256, d2l.try_gpu()\n","num_epochs, lr = 500, 1\n","model = d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_params,\n","                            init_gru_state, gru)\n","d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":19,"id":"aS_dwFYMcm86"},"source":["## Concise Implementation\n","\n","Trong Gluon, ta có thể trực tiếp gọi lớp GRU trong mô-đun rnn. Mô-đun này đóng gói tất cả các cấu hình đã thực hiện tường minh ở trên. Đoạn mã này nhanh hơn đáng kể do sử dụng các toán tử được biên dịch chứ không phải thuần Python như trên.\n"]},{"cell_type":"code","metadata":{"origin_pos":22,"tab":["tensorflow"],"id":"_IpLRrLjcm86","executionInfo":{"status":"aborted","timestamp":1630237592634,"user_tz":-420,"elapsed":7,"user":{"displayName":"Nam Cao Hải","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiCmrl3X4wfKjF82UzLyBPTNB6px2ty7jZ8llyL=s64","userId":"02198006735637931468"}}},"source":["num_inputs = vocab_size\n","gru_layer = nn.GRU(num_inputs, num_hiddens)\n","model = d2l.RNNModel(gru_layer, len(vocab))\n","model = model.to(device)\n","d2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"origin_pos":23,"id":"1ThU41XRcm86"},"source":["## Summary\n","\n","- Các mạng nơ-ron hồi tiếp có cổng nắm bắt các phụ thuộc xa trong chuỗi thời gian tốt hơn.\n","- Cổng xóa giúp nắm bắt phụ thuộc ngắn hạn trong chuỗi thời gian.\n","- Cổng cập nhật giúp nắm bắt các phụ thuộc dài hạn trong chuỗi thời gian.\n","- Trường hợp đặc biệt khi cổng xóa được kích hoạt, GRU trở thành RNN cơ bản. - - Chúng cũng có thể bỏ qua các các thành phần trong chuỗi khi cần.\n","\n","\n","## Exercises\n","\n","- Hãy so sánh thời gian chạy, perplexity và các chuỗi đầu ra của rnn.RNN và rnn.GRU.\n","- Quan sát và phân tích tác động tới thời gian chạy, perplexity và các câu được sinh ra khi điều chỉnh các siêu tham số.\n"]},{"cell_type":"code","metadata":{"id":"NkOXhsbnu2cq"},"source":[""],"execution_count":null,"outputs":[]}]}